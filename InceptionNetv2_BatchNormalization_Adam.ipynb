{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"InceptionNetv2_BatchNormalization_Adam.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"769abc9ea6494b6f9ab6f0c397fe9464":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f18062294dfc41c3af9c451bb60aa61b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0ee36b42d6c64a1a8ba860b375631020","IPY_MODEL_89b2e35f00b24836a5967bd1c99d1cfd"]}},"f18062294dfc41c3af9c451bb60aa61b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ee36b42d6c64a1a8ba860b375631020":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_83823ef5cccf477ab8db4c8108e155c3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f4ac158f5e6d4eb78a99308622f092a5"}},"89b2e35f00b24836a5967bd1c99d1cfd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_96cf451e293b4e7b972efeec2bc1a035","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 169009152/? [00:05&lt;00:00, 28386974.92it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_92109c118a244ba28aeec948096970e4"}},"83823ef5cccf477ab8db4c8108e155c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f4ac158f5e6d4eb78a99308622f092a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96cf451e293b4e7b972efeec2bc1a035":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"92109c118a244ba28aeec948096970e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"ck4axUzxYNLE","executionInfo":{"status":"ok","timestamp":1602905904378,"user_tz":240,"elapsed":5237,"user":{"displayName":"Try It","photoUrl":"","userId":"11883681010807328450"}}},"source":["import torch.nn as nn\n","import torch\n","\n","\n","class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, batch_norm = True):\n","        self.batch_norm = batch_norm\n","        super(ConvBlock, self).__init__()\n","        # Conv2d layers used throughout the model.\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n","        if self.batch_norm:\n","            self.bn = nn.BatchNorm2d(out_channels)\n","        self.act = nn.ReLU()\n","        \n","    def forward(self, x):\n","        x = self.conv(x)\n","        if self.batch_norm:\n","            x = self.bn(x)\n","        x = self.act(x)\n","        return x\n","\n","\n","class InceptionF5(nn.Module):\n","    # Figure 5 defined in Table 1 of the paper: https://arxiv.org/pdf/1512.00567.pdf\n","    def __init__(self, in_channels, batch_norm):\n","        super(InceptionF5, self).__init__()\n","        # Base >> 1X1 Conv. >> 3X3 Conv. >> 3X3 Conv. >> Final Concat\n","        self.inceptionf5_1 = nn.Sequential(\n","            ConvBlock(in_channels, 64, kernel_size=1, stride=1, padding=0, batch_norm = batch_norm),\n","            ConvBlock(64, 96, kernel_size=3, stride=1, padding=1, batch_norm = batch_norm),\n","            ConvBlock(96, 96, kernel_size=3, stride=1, padding=1, batch_norm = batch_norm))\n","        \n","        # Base >> 1X1 Conv. >> 3X3 Conv. >> Final Concat\n","        self.inceptionf5_2 = nn.Sequential(\n","            ConvBlock(in_channels, 48, kernel_size=1, stride=1, padding=0, batch_norm = batch_norm),\n","            ConvBlock(48, 64, kernel_size=3, stride=1, padding=1, batch_norm = batch_norm))\n","        \n","        # Base >> Pool. >> 1X1 Conv. >> Final Concat\n","        self.inceptionf5_3 = nn.Sequential(\n","            nn.MaxPool2d(3, stride=1, padding=1),\n","            ConvBlock(in_channels, 64, kernel_size=1, stride=1, padding=0, batch_norm = batch_norm))\n","            \n","        # Base >> 1X1 Conv. >> Final Concat\n","        self.inceptionf5_4 = nn.Sequential(\n","            ConvBlock(in_channels, 64, kernel_size=1, stride=1, padding=0, batch_norm = batch_norm))\n","        \n","    def forward(self, x):\n","        inceptionf5_1 = self.inceptionf5_1(x)\n","        inceptionf5_2 = self.inceptionf5_2(x)\n","        inceptionf5_3 = self.inceptionf5_3(x)\n","        inceptionf5_4 = self.inceptionf5_4(x)\n","        return torch.cat([inceptionf5_1, inceptionf5_2, inceptionf5_3, inceptionf5_4], 1)\n","\n","\n","class InceptionF6(nn.Module):\n","    # Figure 6 defined in Table 1 of the paper: https://arxiv.org/pdf/1512.00567.pdf\n","    def __init__(self, in_channels, f_7x7, batch_norm):\n","        super(InceptionF6, self).__init__()\n","        # Base >> 1X1 Conv. >> 1Xn Conv. >> nX1 Conv. >> 1Xn Conv. >> nX1 Conv. >> Final Concat\n","        self.inceptionf6_1 = nn.Sequential(\n","            ConvBlock(in_channels, f_7x7, kernel_size=1, stride=1, padding=0, batch_norm = batch_norm),\n","            ConvBlock(f_7x7, f_7x7, kernel_size=(1,7), stride=1, padding=(0,3), batch_norm = batch_norm),\n","            ConvBlock(f_7x7, f_7x7, kernel_size=(7,1), stride=1, padding=(3,0), batch_norm = batch_norm),\n","            ConvBlock(f_7x7, f_7x7, kernel_size=(1,7), stride=1, padding=(0,3), batch_norm = batch_norm),\n","            ConvBlock(f_7x7, 192, kernel_size=(7,1), stride=1, padding=(3,0), batch_norm = batch_norm))\n","        \n","        # Base >> 1X1 Conv. >> 1X7 Conv. >> 7X1 Conv. >> Final Concat\n","        self.inceptionf6_2 = nn.Sequential(\n","            ConvBlock(in_channels, f_7x7, kernel_size=1, stride=1, padding=0, batch_norm = batch_norm),\n","            ConvBlock(f_7x7, f_7x7, kernel_size=(1,7), stride=1, padding=(0,3), batch_norm = batch_norm),\n","            ConvBlock(f_7x7, 192, kernel_size=(7,1), stride=1, padding=(3,0), batch_norm = batch_norm))\n","         \n","        # Base >> Pool. >> 1X1 Conv. >> Final Concat       \n","        self.inceptionf6_3 = nn.Sequential(\n","            nn.MaxPool2d(3, stride=1, padding=1),\n","            ConvBlock(in_channels, 192, kernel_size=1, stride=1, padding=0, batch_norm = batch_norm))\n","        \n","        # Base >> 1X1 Conv. >> Final Concat\n","        self.inceptionf6_4 = nn.Sequential(\n","            ConvBlock(in_channels, 192, kernel_size=1, stride=1, padding=0, batch_norm = batch_norm))\n","        \n","    def forward(self, x):\n","        inceptionf6_1 = self.inceptionf6_1(x)\n","        inceptionf6_2 = self.inceptionf6_2(x)\n","        inceptionf6_3 = self.inceptionf6_3(x)\n","        inceptionf6_4 = self.inceptionf6_4(x)\n","        return torch.cat([inceptionf6_1, inceptionf6_2, inceptionf6_3, inceptionf6_4], 1)\n","\n","\n","class InceptionF7(nn.Module):\n","    # Figure 7 defined in Table 1 of the paper: https://arxiv.org/pdf/1512.00567.pdf\n","    def __init__(self, in_channels, batch_norm):\n","        super(InceptionF7, self).__init__()\n","        # Base >> 1X1 Conv. >> 3X3 Conv. >> 1X3 Conv. Left & 3X1 Conv. Right >> Final Concat\n","        self.inceptionf7_1 = nn.Sequential(\n","            ConvBlock(in_channels, 448, kernel_size=1, stride=1, padding=0, batch_norm = batch_norm),\n","            ConvBlock(448, 384, kernel_size=(3,3), stride=1, padding=1, batch_norm = batch_norm))\n","        self.inceptionf7_1_left = ConvBlock(384, 384, kernel_size=(1,3), stride=1, padding=(0,1), batch_norm = batch_norm)\n","        self.inceptionf7_1_right = ConvBlock(384, 384, kernel_size=(3,1), stride=1, padding=(1,0), batch_norm = batch_norm)\n","        \n","        # Base >> 1X1 Conv. >> 1X3 Conv. Left & 3X1 Conv. Right >> Final Concat\n","        self.inceptionf7_2 = ConvBlock(in_channels, 384, kernel_size=1, stride=1, padding=0, batch_norm = batch_norm)\n","        self.inceptionf7_2_left = ConvBlock(384, 384, kernel_size=(1,3), stride=1, padding=(0,1), batch_norm = batch_norm)\n","        self.inceptionf7_2_right = ConvBlock(384, 384, kernel_size=(3,1), stride=1, padding=(1,0), batch_norm = batch_norm)\n","        \n","        # Base >> Pool. >> 1X1 Conv. >> Final Concat       \n","        self.inceptionf7_3 = nn.Sequential(\n","            nn.MaxPool2d(3, stride=1, padding=1),\n","            ConvBlock(in_channels, 192, kernel_size=1, stride=1, padding=0, batch_norm = batch_norm))\n","        \n","        # Base >> 1X1 Conv. >> Final Concat\n","        self.inceptionf7_4 = nn.Sequential(\n","            ConvBlock(in_channels, 320, kernel_size=1, stride=1, padding=0, batch_norm = batch_norm))\n","        \n","    def forward(self, x):\n","        inceptionf7_1 = self.inceptionf7_1(x)\n","        inceptionf7_1 = torch.cat([self.inceptionf7_1_left(inceptionf7_1), self.inceptionf7_1_right(inceptionf7_1)], 1)\n","        inceptionf7_2 = self.inceptionf7_2(x)\n","        inceptionf7_2 = torch.cat([self.inceptionf7_2_left(inceptionf7_2), self.inceptionf7_2_right(inceptionf7_2)], 1)\n","        inceptionf7_3 = self.inceptionf7_3(x)\n","        inceptionf7_4 = self.inceptionf7_4(x)\n","        \n","        return torch.cat([inceptionf7_1, inceptionf7_2, inceptionf7_3, inceptionf7_4], 1)\n","\n","\n","class InceptionRed(nn.Module):\n","    # Figure 10 of the paper: https://arxiv.org/pdf/1512.00567.pdf\n","    # Reduction blocks to reduce the grid sizes between the Inception blocks and imporve pooling operations. \n","    def __init__(self, in_channels, f_3x3_r, add_ch=0, batch_norm = True):\n","        super(InceptionRed, self).__init__()\n","        # Base >> 1X1 Conv. >> 3X3 Conv. >> 3X3 Conv. >> Final Concat\n","        self.inceptionred_1 = nn.Sequential(\n","            ConvBlock(in_channels, f_3x3_r, kernel_size=1, stride=1, padding=0, batch_norm = batch_norm),\n","            ConvBlock(f_3x3_r, 178 + add_ch, kernel_size=3, stride=1, padding=1, batch_norm = batch_norm),\n","            ConvBlock(178 + add_ch, 178 + add_ch, kernel_size=3, stride=2, padding=0, batch_norm = batch_norm))\n","        \n","        # Base >> 1X1 Conv. >> 3X3 Conv. >> Final Concat\n","        self.inceptionred_2 = nn.Sequential(\n","            ConvBlock(in_channels, f_3x3_r, kernel_size=1, stride=1, padding=0, batch_norm = batch_norm),\n","            ConvBlock(f_3x3_r, 302 + add_ch, kernel_size=3, stride=2, padding=0, batch_norm = batch_norm))\n","        \n","        # Base >> Pool. >> Final Concat\n","        self.inceptionred_3 = nn.Sequential(\n","            nn.MaxPool2d(3, stride=2, padding=0))\n","        \n","    def forward(self, x):\n","        inceptionred_1 = self.inceptionred_1(x)\n","        inceptionred_2 = self.inceptionred_2(x)\n","        inceptionred_3 = self.inceptionred_3(x)\n","        return torch.cat([inceptionred_1, inceptionred_2, inceptionred_3], 1)\n","\n","\n","class InceptionAux(nn.Module):\n","    # Auxiliary Classifier from the paper: https://arxiv.org/pdf/1512.00567.pdf\n","    def __init__(self, in_channels, num_classes):\n","        super(InceptionAux, self).__init__()\n","        self.pool = nn.AdaptiveAvgPool2d((4,4))\n","        self.conv = nn.Conv2d(in_channels, 128, kernel_size=1, stride=1, padding=0)\n","        self.relu = nn.ReLU()\n","        self.fc1 = nn.Linear(2048, 1024)\n","        self.dropout = nn.Dropout(0.7)\n","        self.fc2 = nn.Linear(1024, num_classes)\n","    \n","    def forward(self, x):\n","        x = self.pool(x)\n","        x = self.conv(x)\n","        x = self.relu(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x\n","\n","\n","\n","class InceptionV2(nn.Module):\n","    def __init__(self, num_classes = 100, batch_norm = True, dropout = True, init_weights=True, aux_logits=True):\n","        super(InceptionV2, self).__init__()\n","        self.dropout = dropout\n","        self.aux_logits = aux_logits\n","        # Intial Conv. layers and MaxPool before Inception layers. \n","        self.conv1 = ConvBlock(3, 32, kernel_size=3, stride=2, padding=0, batch_norm = batch_norm)\n","        self.conv2 = ConvBlock(32, 32, kernel_size=3, stride=1, padding=0, batch_norm = batch_norm)\n","        self.conv3 = ConvBlock(32, 64, kernel_size=3, stride=1, padding=1, batch_norm = batch_norm)\n","        self.pool1 = nn.MaxPool2d(3, stride=2, padding=0)\n","        self.conv4 = ConvBlock(64, 80, kernel_size=3, stride=1, padding=0, batch_norm = batch_norm)\n","        self.conv5 = ConvBlock(80, 192, kernel_size=3, stride=2, padding=0, batch_norm = batch_norm)\n","        self.conv6 = ConvBlock(192, 288, kernel_size=3, stride=1, padding=1, batch_norm = batch_norm)\n","        # Inception layers (F5)\n","        self.inception3a = InceptionF5(288, batch_norm = batch_norm)\n","        self.inception3b = InceptionF5(288, batch_norm = batch_norm)\n","        self.inception3c = InceptionF5(288, batch_norm = batch_norm)\n","        # Reduction layer\n","        self.inceptionRed1 = InceptionRed(288,f_3x3_r=64, add_ch=0, batch_norm = batch_norm)\n","        # Inception layers (F6)\n","        self.inception4a = InceptionF6(768, f_7x7=128, batch_norm = batch_norm)\n","        self.inception4b = InceptionF6(768, f_7x7=160, batch_norm = batch_norm)\n","        self.inception4c = InceptionF6(768, f_7x7=160, batch_norm = batch_norm)\n","        self.inception4d = InceptionF6(768, f_7x7=160, batch_norm = batch_norm)\n","        self.inception4e = InceptionF6(768, f_7x7=192, batch_norm = batch_norm)\n","        # Reduction layer\n","        self.inceptionRed2 = InceptionRed(768,f_3x3_r=192, add_ch=16, batch_norm = batch_norm)\n","        # if self.aux_logits:\n","        self.aux = InceptionAux(768, num_classes) \n","        # Inception layers (F7)\n","        self.inception5a = InceptionF7(1280, batch_norm = batch_norm)\n","        self.inception5b = InceptionF7(2048, batch_norm = batch_norm)\n","        # AdaptivePooling and Fully Connected \n","        self.pool6 = nn.AdaptiveAvgPool2d((1,1))\n","        if dropout:\n","            self.dropout = nn.Dropout(0.4)\n","        self.fc = nn.Linear(2048, num_classes)\n","\n","        if init_weights:\n","            for m in self.modules():\n","                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n","                    import scipy.stats as stats\n","                    stddev = m.stddev if hasattr(m, 'stddev') else 0.1\n","                    X = stats.truncnorm(-2, 2, scale=stddev)\n","                    values = torch.as_tensor(X.rvs(m.weight.numel()), dtype=m.weight.dtype)\n","                    values = values.view(m.weight.size())\n","                    with torch.no_grad():\n","                        m.weight.copy_(values)\n","                elif isinstance(m, nn.BatchNorm2d):\n","                    nn.init.constant_(m.weight, 1)\n","                    nn.init.constant_(m.bias, 0)\n","    \n","    def forward(self, x):\n","        # Intial Conv. layers and MaxPool before Inception layers. \n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.pool1(x)\n","        x = self.conv4(x)\n","        x = self.conv5(x)\n","        x = self.conv6(x)\n","        # Inception layers (F5)\n","        x = self.inception3a(x)\n","        x = self.inception3b(x)\n","        x = self.inception3c(x)\n","        # Reduction layer\n","        x = self.inceptionRed1(x)\n","        # Inception layers (F6)\n","        x = self.inception4a(x)\n","        x = self.inception4b(x)\n","        x = self.inception4c(x)\n","        x = self.inception4d(x)\n","        x = self.inception4e(x)\n","        # if self.aux_logits:\n","        aux = self.aux(x)\n","        # else:\n","        #     aux = None\n","        x = self.inceptionRed2(x) \n","        # Inception layers (F7)\n","        x = self.inception5a(x)\n","        x = self.inception5b(x)\n","        # AdaptivePooling and Fully Connected \n","        x = self.pool6(x)\n","        if self.dropout:\n","            x = self.dropout(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","        \n","        return x, aux\n","\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"I-88CtrPo0Hi","executionInfo":{"status":"ok","timestamp":1602905934656,"user_tz":240,"elapsed":742,"user":{"displayName":"Try It","photoUrl":"","userId":"11883681010807328450"}},"outputId":"b948415d-4e1f-44d7-e48f-58e34870254f","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = model = InceptionV2(batch_norm = True, dropout = True, init_weights=False) \n","\n","model"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["InceptionV2(\n","  (conv1): ConvBlock(\n","    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))\n","    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU()\n","  )\n","  (conv2): ConvBlock(\n","    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n","    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU()\n","  )\n","  (conv3): ConvBlock(\n","    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU()\n","  )\n","  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv4): ConvBlock(\n","    (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1))\n","    (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU()\n","  )\n","  (conv5): ConvBlock(\n","    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(2, 2))\n","    (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU()\n","  )\n","  (conv6): ConvBlock(\n","    (conv): Conv2d(192, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (act): ReLU()\n","  )\n","  (inception3a): InceptionF5(\n","    (inceptionf5_1): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf5_2): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf5_3): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n","      (1): ConvBlock(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf5_4): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","  )\n","  (inception3b): InceptionF5(\n","    (inceptionf5_1): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf5_2): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf5_3): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n","      (1): ConvBlock(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf5_4): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","  )\n","  (inception3c): InceptionF5(\n","    (inceptionf5_1): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf5_2): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf5_3): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n","      (1): ConvBlock(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf5_4): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","  )\n","  (inceptionRed1): InceptionRed(\n","    (inceptionred_1): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(64, 178, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(178, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(178, 178, kernel_size=(3, 3), stride=(2, 2))\n","        (bn): BatchNorm2d(178, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionred_2): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(64, 302, kernel_size=(3, 3), stride=(2, 2))\n","        (bn): BatchNorm2d(302, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionred_3): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    )\n","  )\n","  (inception4a): InceptionF6(\n","    (inceptionf6_1): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (3): ConvBlock(\n","        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (4): ConvBlock(\n","        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_2): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_3): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n","      (1): ConvBlock(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_4): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","  )\n","  (inception4b): InceptionF6(\n","    (inceptionf6_1): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (3): ConvBlock(\n","        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (4): ConvBlock(\n","        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_2): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_3): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n","      (1): ConvBlock(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_4): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","  )\n","  (inception4c): InceptionF6(\n","    (inceptionf6_1): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (3): ConvBlock(\n","        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (4): ConvBlock(\n","        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_2): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_3): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n","      (1): ConvBlock(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_4): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","  )\n","  (inception4d): InceptionF6(\n","    (inceptionf6_1): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (3): ConvBlock(\n","        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (4): ConvBlock(\n","        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_2): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_3): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n","      (1): ConvBlock(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_4): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","  )\n","  (inception4e): InceptionF6(\n","    (inceptionf6_1): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (3): ConvBlock(\n","        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (4): ConvBlock(\n","        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_2): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_3): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n","      (1): ConvBlock(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf6_4): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","  )\n","  (inceptionRed2): InceptionRed(\n","    (inceptionred_1): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(192, 194, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(194, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (2): ConvBlock(\n","        (conv): Conv2d(194, 194, kernel_size=(3, 3), stride=(2, 2))\n","        (bn): BatchNorm2d(194, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionred_2): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(192, 318, kernel_size=(3, 3), stride=(2, 2))\n","        (bn): BatchNorm2d(318, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionred_3): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    )\n","  )\n","  (aux): InceptionAux(\n","    (pool): AdaptiveAvgPool2d(output_size=(4, 4))\n","    (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n","    (relu): ReLU()\n","    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n","    (dropout): Dropout(p=0.7, inplace=False)\n","    (fc2): Linear(in_features=1024, out_features=100, bias=True)\n","  )\n","  (inception5a): InceptionF7(\n","    (inceptionf7_1): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf7_1_left): ConvBlock(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n","      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU()\n","    )\n","    (inceptionf7_1_right): ConvBlock(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n","      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU()\n","    )\n","    (inceptionf7_2): ConvBlock(\n","      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1))\n","      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU()\n","    )\n","    (inceptionf7_2_left): ConvBlock(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n","      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU()\n","    )\n","    (inceptionf7_2_right): ConvBlock(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n","      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU()\n","    )\n","    (inceptionf7_3): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n","      (1): ConvBlock(\n","        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf7_4): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","  )\n","  (inception5b): InceptionF7(\n","    (inceptionf7_1): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf7_1_left): ConvBlock(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n","      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU()\n","    )\n","    (inceptionf7_1_right): ConvBlock(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n","      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU()\n","    )\n","    (inceptionf7_2): ConvBlock(\n","      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1))\n","      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU()\n","    )\n","    (inceptionf7_2_left): ConvBlock(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n","      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU()\n","    )\n","    (inceptionf7_2_right): ConvBlock(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n","      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU()\n","    )\n","    (inceptionf7_3): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n","      (1): ConvBlock(\n","        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","    (inceptionf7_4): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1))\n","        (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act): ReLU()\n","      )\n","    )\n","  )\n","  (pool6): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (dropout): Dropout(p=0.4, inplace=False)\n","  (fc): Linear(in_features=2048, out_features=100, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"6b82L0zKbaqn"},"source":["%reload_ext tensorboard\n","\n","LOG_DIR = \"/content/drive/My Drive/Deep Learning Assignment/logs\"\n","\n","import os   \n","import datetime\n","import tensorflow as tf  \n","tensorboard_callback = tf.keras.callbacks.TensorBoard(LOG_DIR, histogram_freq=1)\n","%tensorboard --logdir='/content/drive/My Drive/Deep Learning Assignment/logs'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1xuQLm6DYYgD"},"source":["import torch.optim as optim\n","import torchvision\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","import torchvision.transforms as transforms\n","import time\n","from datetime import datetime\n","import os\n","import torch\n","import numpy as np\n","from sklearn.metrics import precision_score, recall_score, accuracy_score\n","import torch.nn as nn\n","from torchvision import models\n","\n","\n","def train(epoch):\n","    start = time.time() \n","    y_pred = []\n","    y_true = []   \n","\n","    # Run model in training mode\n","    model.train()\n","\n","    for batch_index, (images, labels) in enumerate(training_loader):\n","        iter_num = (epoch - 1) * len(training_loader) + batch_index + 1\n","        # Convert the inputs to GPU compatible tensors. \n","        if cuda_available:\n","            images = images.cuda()\n","            labels = labels.cuda()\n","\n","        # Learning on the training data\n","        optimizer.zero_grad()\n","        # outputs = model(images)\n","        output0, output1 = model(images)\n","            \n","        # Compute the loss.\n","        loss0 = loss_function(output0, labels)\n","        loss1 = loss_function(output1, labels)\n","        loss = loss0 + 0.3 * loss1\n","        # loss = loss_function(outputs, labels)\n","\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), 1)\n","        optimizer.step()\n","\n","        output_values, predicted = output0.max(1)\n","        y_pred.extend(predicted.cpu().tolist())\n","        y_true.extend(labels.cpu().tolist())\n","\n","        # Printing the training results and storing them to tensorboard\n","        print('Training Epoch: {epoch} [{num_trained}/{num_samples}]\\tLoss: {:0.2f}'.format(\n","            loss.item(),\n","            epoch = epoch,\n","            num_trained = batch_index * batch_size + len(images),\n","            num_samples = len(training_loader.dataset)))\n","        writer.add_scalar('Train: Loss', loss.item(), iter_num)\n","        \n","    # Calculating Metrics\n","    accuracy = accuracy_score(y_true, y_pred)\n","\n","    # Time consumed for a epoch\n","    time_consumed = time.time() - start\n","    print('Time taken to train epoch {epoch}: {:.2f}s'.format(time_consumed, epoch = epoch))\n","    writer.add_scalar('Train Set: Accuracy', accuracy, epoch)\n","\n","\n","\n","@torch.no_grad()\n","def test(epoch):\n","    test_loss = 0.0\n","    y_pred = []\n","    y_true = []\n","    len_test_loader = len(test_loader.dataset)\n","    start = time.time()\n","    \n","    # Run model in evaluation mode\n","    model.eval()\n","\n","    for (images, labels) in test_loader:\n","        # Convert the inputs to GPU compatible tensors. \n","        if cuda_available:\n","            images = images.cuda()\n","            labels = labels.cuda()\n","\n","        # Predicting labels of test image set\n","        # model_outputs = model(images)\n","        output0, output1 = model(images)\n","            \n","        # Compute the loss.\n","        loss0 = loss_function(output0, labels)\n","        loss1 = loss_function(output1, labels)\n","        model_loss = loss0 + 0.3 * loss1\n","        # model_loss = loss_function(model_outputs, labels)\n","\n","        test_loss += model_loss.item()\n","        output_values, predicted = output0.max(1)\n","        y_pred.extend(predicted.cpu().tolist())\n","        y_true.extend(labels.cpu().tolist())\n","        \n","    # Calculating Metrics\n","    accuracy = accuracy_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred, average='macro', zero_division=1)\n","    precision = precision_score(y_true, y_pred, average='macro', zero_division=1)\n","    loss = test_loss / len_test_loader\n","    time_consumed = time.time() - start\n","\n","    # GPU stats\n","    # if cuda_available:\n","    #     print(torch.cuda.memory_summary())\n","\n","    # Printing the testing results and storing them to tensorboard\n","    print('Testing Network for epoch: ', epoch)\n","    print('Evaluation: Evaluation Time: {:.2f}s, Average loss: {:.4f}, Accuracy: {:.4f}, Recall: {:.4f}, Precision: {:.4f}'.format(time_consumed, loss, accuracy, recall, precision))\n","    writer.add_scalar('Test Set: Average loss', loss, epoch)\n","    writer.add_scalar('Test Set: Accuracy', accuracy, epoch)\n","    return accuracy, test_loss\n","\n","\n","global cuda_available\n","global writer\n","global batch_size\n","DATA_ROOT = './data'\n","batch_size = 256\n","epochs = 200\n","min_early_stopping = 150\n","patience = 20\n","milestones = [50, 100, 150]\n","LOG_DIR = '/content/drive/My Drive/Deep Learning Assignment/logs'\n","checkpoints_path = '/content/drive/My Drive/Deep Learning Assignment/checkpoints'\n","batch_norm = True\n","dropout = False\n","\n","\n","setting = ''\n","if dropout:\n","    setting = 'Dropout'\n","elif batch_norm:\n","    setting = 'BatchNormalization'\n","else:\n","    setting = 'NoRegularization'\n","\n","# Method to compute mean and std. \n","# def compute_mean_std(cifar100_dataset):\n","#     data_r = numpy.dstack([cifar100_dataset[i][1][:, :, 0] for i in range(len(cifar100_dataset))])\n","#     data_g = numpy.dstack([cifar100_dataset[i][1][:, :, 1] for i in range(len(cifar100_dataset))])\n","#     data_b = numpy.dstack([cifar100_dataset[i][1][:, :, 2] for i in range(len(cifar100_dataset))])\n","#     mean = numpy.mean(data_r), numpy.mean(data_g), numpy.mean(data_b)\n","#     std = numpy.std(data_r), numpy.std(data_g), numpy.std(data_b)\n","#     return mean, std\n","\n","# mean and std are computed on the training set. \n","mean = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n","std = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n","\n","\n","transform_train = transforms.Compose([\n","    transforms.Resize((96,96)),\n","    transforms.RandomCrop(96, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std)\n","])\n","\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize((96,96)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std)\n","])\n","\n","# Load training data from CIFAR100\n","train_data = torchvision.datasets.CIFAR100(root=DATA_ROOT, train=True, download=True, transform=transform_train)\n","training_loader = DataLoader(train_data, shuffle=True, num_workers=4, batch_size=batch_size)\n","\n","# Load testing data from CIFAR100\n","test_data = torchvision.datasets.CIFAR100(root=DATA_ROOT, train=False, download=True, transform=transform_test)\n","test_loader = DataLoader(test_data, shuffle=True, num_workers=4, batch_size=batch_size)\n","\n","# Model\n","model = model = InceptionV2(batch_norm = batch_norm, dropout = dropout, init_weights=True) \n","print(model)\n","\n","# Check if any GPU is available\n","cuda_available = torch.cuda.is_available()\n","if torch.cuda.is_available():\n","    model.cuda()             # Convert the model to GPU compatible. \n","\n","# Define Loss Function, Optimizer\n","loss_function = nn.CrossEntropyLoss()\n","# optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n","scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.2) \n","\n","# Tensorboard\n","log_model_path = os.path.join(LOG_DIR, \n","                              '{model}_{setting}_{optimizer}'.format(model=str(model.__class__.__name__), \n","                               setting=setting, \n","                               optimizer=optimizer.__class__.__name__))\n","if not os.path.exists(log_model_path):\n","    os.mkdir(log_model_path)\n","writer = SummaryWriter(log_dir=os.path.join(log_model_path, datetime.now().strftime('%d_%B_%Y_%Hh_%Mm_%Ss')))\n","dummy_input_tensor = torch.Tensor(1, 3, 96, 96).cuda()\n","writer.add_graph(model, dummy_input_tensor)\n","\n","# Checkpoints folder to save model\n","if not os.path.exists(checkpoints_path):\n","    os.makedirs(checkpoints_path)\n","checkpoints_path = os.path.join(checkpoints_path, '{model}_{setting}_{optimizer}')\n","\n","# Initialize the early_stopping_counter.\n","early_stopping_counter = 0\n","\n","# Train and Evaluting the model\n","min_validation_loss = float('inf')\n","for epoch in range(1, epochs):\n","    # Adaptive Learning Rate\n","    scheduler.step(epoch)\n","    # Checking for early stopping condition. \n","    if early_stopping_counter > patience and epoch >= min_early_stopping:\n","        print(\"Early Stopping the model training as there no significant improvment in the eval loss.\")\n","        break\n","    train(epoch)\n","    accuracy, validation_loss = test(epoch)\n","    if validation_loss < min_validation_loss:\n","        torch.save(model.state_dict(), checkpoints_path.format(\n","            model=str(model.__class__.__name__), \n","            setting=setting, \n","            optimizer=str(optimizer.__class__.__name__)))\n","        min_validation_loss = validation_loss\n","        early_stopping_counter = 0\n","    else: \n","        early_stopping_counter += 1 \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mfj6hVfwYauc","executionInfo":{"status":"ok","timestamp":1602868448414,"user_tz":240,"elapsed":23014,"user":{"displayName":"Try It","photoUrl":"","userId":"11883681010807328450"}},"outputId":"8b87dc5c-cd55-4da5-d38a-7b6adda30a4e","colab":{"base_uri":"https://localhost:8080/","height":219,"referenced_widgets":["769abc9ea6494b6f9ab6f0c397fe9464","f18062294dfc41c3af9c451bb60aa61b","0ee36b42d6c64a1a8ba860b375631020","89b2e35f00b24836a5967bd1c99d1cfd","83823ef5cccf477ab8db4c8108e155c3","f4ac158f5e6d4eb78a99308622f092a5","96cf451e293b4e7b972efeec2bc1a035","92109c118a244ba28aeec948096970e4"]}},"source":["# Run this code bloack to load the model and compute different metrics on validation dataset.  \n","from sklearn.metrics import precision_score, recall_score, accuracy_score\n","import torchvision.transforms as transforms\n","import os\n","import torch.optim as optim\n","import torchvision\n","import torch\n","from torch.utils.data import DataLoader\n","import sys\n","\n","\n","mean = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n","std = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n","\n","batch_norm = True\n","dropout = False\n","setting = ''\n","if dropout:\n","    setting = 'Dropout'\n","elif batch_norm:\n","    setting = 'BatchNormalization'\n","else:\n","    setting = 'NoRegularization'\n","\n","DATA_ROOT = './data'\n","checkpoints_path = '/content/drive/My Drive/Deep Learning Assignment/checkpoints'\n","checkpoints_path = os.path.join(checkpoints_path, '{model}_{setting}_{optimizer}')\n","batch_size = 256\n","device = 'cpu'\n","try:\n","    model = model = InceptionV2(batch_norm = batch_norm, dropout = dropout, init_weights=False) #, init_weights=True)\n","except Exception as e:\n","    sys.exit(\"Please load the model by running the first block.\")\n","\n","if torch.cuda.is_available():\n","    device = 'cuda'\n","    model.cuda()\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize((96,96)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std)])\n","\n","# Load testing data from CIFAR100\n","test_data = torchvision.datasets.CIFAR100(root=DATA_ROOT, train=False, download=True, transform=transform_test)\n","test_loader = DataLoader(test_data, shuffle=True, num_workers=4, batch_size=batch_size)\n","cuda_available = torch.cuda.is_available()\n","\n","print(\"Model Weights at path: \", checkpoints_path.format(\n","            model=str(model.__class__.__name__), \n","            setting=setting, \n","            optimizer=str(optimizer.__class__.__name__)))\n","# Load model weights.\n","model.load_state_dict(torch.load(checkpoints_path.format(\n","            model=str(model.__class__.__name__), \n","            setting=setting, \n","            optimizer=str(optimizer.__class__.__name__)), map_location=torch.device(device)))\n","\n","\n","\n","model.eval()\n","accuracy = 0.0\n","precision = 0.0\n","recall = 0\n","\n","with torch.no_grad():\n","    y_pred = []\n","    y_true = []\n","    for iter, (image, labels) in enumerate(test_loader):\n","        # print(\"iteration: {}\\ttotal {} iterations\".format(iter + 1, len(test_loader)))\n","        # Convert the inputs to GPU compatible tensors. \n","        if cuda_available:\n","            image = image.cuda()\n","            label = labels.cuda()\n","        # Predicting\n","        output0, output1 = model(image)\n","        output_values, predicted = output0.max(1)\n","\n","        y_pred.extend(predicted.cpu().tolist())\n","        y_true.extend(labels.cpu().tolist())\n","\n","accuracy = accuracy_score(y_true, y_pred)\n","recall = recall_score(y_true, y_pred, labels=range(100), average = 'macro')#average='macro', zero_division=1)\n","precision = precision_score(y_true, y_pred, average='macro', zero_division=1)\n","\n","print('\\n')\n","print(\"Model Setting: \", '{model}_{setting}_{optimizer}'.format(\n","            model=str(model.__class__.__name__), \n","            setting=setting, \n","            optimizer=str(optimizer.__class__.__name__)))\n","\n","\n","print(\"Accuracy: \", accuracy)\n","print(\"Precision: \", precision)\n","print(\"Recall: \", recall)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"769abc9ea6494b6f9ab6f0c397fe9464","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/cifar-100-python.tar.gz to ./data\n","Model Weights at path:  /content/drive/My Drive/Deep Learning Assignment/checkpoints/InceptionV2_BatchNormalization_Adam\n","\n","\n","\n","Model Setting:  InceptionV2_BatchNormalization_Adam\n","Accuracy:  0.636\n","Precision:  0.6380864105632366\n","Recall:  0.6359999999999999\n"],"name":"stdout"}]}]}